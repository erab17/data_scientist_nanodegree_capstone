# Data Scientist Nanodegree Capstone Project
## Starbuck's Capstone Challange

Link to blog post for this project: 
https://medium.com/@jerker.aberg/starbucks-capstone-project-8165e4feaf9d

## Table of Contents
1) Libraries used  
2) Motivation  
3) Relevant files  
4) Summary  
5) Acknowledgement  

## Libraries Used:
Pandas  
Math  
Numpy  
pdb  
tqdm  
matplotlib  
seaborn  
sklearn  
scipy  
shap  
category_encoders  
tpot  
json  

## Motivation
For this project the goal was to combine the different datasets and create a supervised machine learning model that tries to predict the transaction amount. To accomplise this target the data was explored, visualized and processed. The data consisted of three data sets: user specific data, promotional data and transaction data.

## Relevant files
Starbucks_Capstone_notebook-Copy1.ipynb: Jupyter notebook file where all the data exploraton, visualization, processing and modelling took place.  
df2.csv: Dataframe file that contain the final dataframe with all engineered feeatures that is used to try to predict the transaction amount. It is saved as a file that the user can import as it takes a while to generate.  
df_res.csv: Dataframe file that contains all the results from the pipeline study. Here different encoders, regressors, imputation techiniqes, relabeling threshold  and scalers are iterated over in order to see how large the difference is between the different configuratons. This is saved as a csv file since it takes quite some time to generate it.  
tpot_pipeline.py: Python file generated by the TPOT module. Again this method takes quite some time to run, in order to avoid running it again one can import the final best   model.  
portfolio.json: Data file that contain the promotion data.  
profile.json: Data file that contain user specific data.  
transcript.json: Data file that contain all the transactional data.  

## Acknowledgement
Thanks to Starbucks and Udacity that provided this data and oppertunity. 
